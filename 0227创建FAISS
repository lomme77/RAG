from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# 读取md文件
md_file_path = "smic.md"  # 这里替换为你的.md文件路径

with open(md_file_path, "r", encoding="utf-8") as file:
    md_text = file.read()

# 按空行拆分文本，分割为文档块
docs = md_text.split("\n\n")
docs = [doc.strip() for doc in docs if doc.strip()]  # 清理空白行

output_file_path = "smic_docs.txt"  # 输出文件路径，可以修改为你想要的路径
with open(output_file_path, "w", encoding="utf-8") as file:
    for doc in docs:
        file.write(doc + "\n\n") 
# 将每个文档块转换为 Document 对象
documents = [Document(page_content=doc) for doc in docs]

# 配置模型路径和设备
modelPath = "sentence-transformers/all-MiniLM-l6-v2"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': False}

# 使用 HuggingFaceEmbeddings 初始化
embeddings = HuggingFaceEmbeddings(
    model_name=modelPath,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)

# 将文本块转换为嵌入向量
vector_store = FAISS.from_documents(documents, embeddings)

# 保存到本地
vector_store.save_local("smic_faiss_index")

# 加载 FAISS 索引
db = FAISS.load_local("smic_faiss_index", embeddings, allow_dangerous_deserialization=True)

# 执行查询，假设你有一个查询字符串
query = "研发投入占营业收入的比例"
query_vector = embeddings.embed_query(query)

# 执行相似度搜索
results = db.similarity_search(query, k=5)
print(results)


